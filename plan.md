# ALP

0. Introduction

1. Data and method
    - the entire archaic corpus as I have it in 4ky (sourced from CDLI + fixed metadata in some tablets)
    - four ways of tokenizing the texts
        - tf-idf vectorizer
        - five true/false classes: so overall 20 models with probability measures

2. Results

3. Discussion

4. Other remarks
    - tf-idf ignores where in the text a given word appears
    - the account types are not as meaningful as they could be; still, they can be used for statistical analysis of sign use